{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ccuulinay/anaconda3/envs/tf2_0/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:523: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/ccuulinay/anaconda3/envs/tf2_0/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:524: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/ccuulinay/anaconda3/envs/tf2_0/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/ccuulinay/anaconda3/envs/tf2_0/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/ccuulinay/anaconda3/envs/tf2_0/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/ccuulinay/anaconda3/envs/tf2_0/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:532: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "/home/ccuulinay/anaconda3/envs/tf2_0/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/ccuulinay/anaconda3/envs/tf2_0/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/ccuulinay/anaconda3/envs/tf2_0/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/ccuulinay/anaconda3/envs/tf2_0/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/ccuulinay/anaconda3/envs/tf2_0/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/ccuulinay/anaconda3/envs/tf2_0/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pathlib\n",
    "import os\n",
    "import sys\n",
    "import glob\n",
    "import tensorflow as tf\n",
    "# from tensorflow.keras.applications.inception_v3 import preprocess_input\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import preprocessing\n",
    "from IPython.display import Image, display\n",
    "import cv2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocess data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = \"./data\"\n",
    "data_p = pathlib.Path(data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "meta_table = pd.read_csv(\"./_filename_dict.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter is_readable_image == False\n",
    "f_table = meta_table[(meta_table['is_readable_image']) & (meta_table['is_completed_image'])].copy()\n",
    "# f_table = f_table[f_table['_format'] != \".gif\"].copy()\n",
    "f_table.reset_index(drop=True, inplace=True)\n",
    "f_table.fillna(\"\", inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'filenames = [\\'./data/\\' + fname for fname in f_table[\\'_filename\\'].tolist()]\\n\\ndef preprocess_image(image):\\n    image = tf.image.decode_jpeg(image)\\n    return image\\n\\ndef load_and_preprocess_image(path):\\n    image = tf.io.read_file(path)\\n    return preprocess_image(image)\\n\\ndef get_corrupted_image_files(file_list):\\n    cr_list = []\\n    \\n    for i, f in enumerate(filenames):\\n        try:\\n            load_and_preprocess_image(f)\\n        except Exception as e:\\n            cr_list.append((i, f))\\n            \\n    return cr_list\\n\\ncorrupted_images = get_corrupted_image_files(filenames)\\n\\ncorrupted_images_index = [i[0] for i in corrupted_images]\\n\\nf_table = f_table.iloc[~f_table.index.isin(corrupted_images_index)].copy()\\n\\nf_table.reset_index(drop=True, inplace=True)\\nf_table.fillna(\"\", inplace=True)'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"filenames = ['./data/' + fname for fname in f_table['_filename'].tolist()]\n",
    "\n",
    "def preprocess_image(image):\n",
    "    image = tf.image.decode_jpeg(image)\n",
    "    return image\n",
    "\n",
    "def load_and_preprocess_image(path):\n",
    "    image = tf.io.read_file(path)\n",
    "    return preprocess_image(image)\n",
    "\n",
    "def get_corrupted_image_files(file_list):\n",
    "    cr_list = []\n",
    "    \n",
    "    for i, f in enumerate(filenames):\n",
    "        try:\n",
    "            load_and_preprocess_image(f)\n",
    "        except Exception as e:\n",
    "            cr_list.append((i, f))\n",
    "            \n",
    "    return cr_list\n",
    "\n",
    "corrupted_images = get_corrupted_image_files(filenames)\n",
    "\n",
    "corrupted_images_index = [i[0] for i in corrupted_images]\n",
    "\n",
    "f_table = f_table.iloc[~f_table.index.isin(corrupted_images_index)].copy()\n",
    "\n",
    "f_table.reset_index(drop=True, inplace=True)\n",
    "f_table.fillna(\"\", inplace=True)\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "皮鞋      100\n",
       "电池      100\n",
       "糖果       99\n",
       "书本       99\n",
       "油桶       99\n",
       "       ... \n",
       "编织袋      54\n",
       "硬果壳      53\n",
       "玉米衣      53\n",
       "尼龙制品     47\n",
       "家养植物      7\n",
       "Name: sample, Length: 154, dtype: int64"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f_table['sample'].value_counts()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "湿垃圾     3703\n",
       "可回收物    3629\n",
       "有害垃圾    2806\n",
       "干垃圾     2407\n",
       "Name: level0, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f_table['level0'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>_filename</th>\n",
       "      <th>_format</th>\n",
       "      <th>sample</th>\n",
       "      <th>spider_id</th>\n",
       "      <th>level0</th>\n",
       "      <th>level1</th>\n",
       "      <th>is_readable_image</th>\n",
       "      <th>is_completed_image</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>干垃圾_编织袋_36.jpeg</td>\n",
       "      <td>.jpeg</td>\n",
       "      <td>编织袋</td>\n",
       "      <td>36</td>\n",
       "      <td>干垃圾</td>\n",
       "      <td></td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>湿垃圾_食材废料_水产_91.jpg</td>\n",
       "      <td>.jpg</td>\n",
       "      <td>水产</td>\n",
       "      <td>91</td>\n",
       "      <td>湿垃圾</td>\n",
       "      <td>食材废料</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>湿垃圾_过期食品_肉干_7.jpg</td>\n",
       "      <td>.jpg</td>\n",
       "      <td>肉干</td>\n",
       "      <td>7</td>\n",
       "      <td>湿垃圾</td>\n",
       "      <td>过期食品</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>干垃圾_橡皮泥_20.jpg</td>\n",
       "      <td>.jpg</td>\n",
       "      <td>橡皮泥</td>\n",
       "      <td>20</td>\n",
       "      <td>干垃圾</td>\n",
       "      <td></td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>有害垃圾_废含汞温度计、废含汞血压计_水银体温计_84.jpg</td>\n",
       "      <td>.jpg</td>\n",
       "      <td>水银体温计</td>\n",
       "      <td>84</td>\n",
       "      <td>有害垃圾</td>\n",
       "      <td>废含汞温度计、废含汞血压计</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         _filename _format sample  spider_id level0  \\\n",
       "0                  干垃圾_编织袋_36.jpeg   .jpeg    编织袋         36    干垃圾   \n",
       "1               湿垃圾_食材废料_水产_91.jpg    .jpg     水产         91    湿垃圾   \n",
       "2                湿垃圾_过期食品_肉干_7.jpg    .jpg     肉干          7    湿垃圾   \n",
       "3                   干垃圾_橡皮泥_20.jpg    .jpg    橡皮泥         20    干垃圾   \n",
       "4  有害垃圾_废含汞温度计、废含汞血压计_水银体温计_84.jpg    .jpg  水银体温计         84   有害垃圾   \n",
       "\n",
       "          level1  is_readable_image  is_completed_image  \n",
       "0                              True                True  \n",
       "1           食材废料               True                True  \n",
       "2           过期食品               True                True  \n",
       "3                              True                True  \n",
       "4  废含汞温度计、废含汞血压计               True                True  "
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f_table.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "filenames = ['./data/' + fname for fname in f_table['_filename'].tolist()]\n",
    "lv0_labels = f_table['level0'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "labelencoder = preprocessing.LabelEncoder()\n",
    "lv0_labels_encoded = labelencoder.fit_transform(lv0_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n"
     ]
    }
   ],
   "source": [
    "# print(labelencoder.transform(['可回收物', \"有害垃圾\", \"湿垃圾\", \"干垃圾\"]))\n",
    "print(len(labelencoder.classes_))\n",
    "lv0_n_classes = len(labelencoder.classes_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_filenames, test_filenames, raw_labels, test_labels = train_test_split(filenames\n",
    "                                                                        , lv0_labels_encoded\n",
    "                                                                        , train_size=0.9\n",
    "                                                                        , random_state=42)\n",
    "\n",
    "train_filenames, val_filenames, train_labels, val_labels = train_test_split(raw_filenames\n",
    "                                                                        , raw_labels\n",
    "                                                                        , train_size=0.9\n",
    "                                                                        , random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10161 10161\n",
      "1129 1129\n",
      "1255 1255\n"
     ]
    }
   ],
   "source": [
    "print(len(train_filenames), len(train_labels))\n",
    "print(len(val_filenames), len(val_labels))\n",
    "print(len(test_filenames), len(test_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = tf.data.Dataset.from_tensor_slices(\n",
    "  (tf.constant(train_filenames), tf.constant(train_labels))\n",
    ")\n",
    "val_data = tf.data.Dataset.from_tensor_slices(\n",
    "  (tf.constant(val_filenames), tf.constant(val_labels))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMAGE_SIZE = 149\n",
    "BATCH_SIZE = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _parse_fn(filename, label):\n",
    "    try:\n",
    "        # read file as byte\n",
    "        image_string = tf.io.read_file(filename)\n",
    "        # decode as string \n",
    "        image_decoded = tf.image.decode_jpeg(image_string, channels=3)\n",
    "        # image_decoded = tf.image.decode_gif(image_string)\n",
    "        ## P.S tf.image.decode_image return shapeless tensor.\n",
    "        # image_decoded = tf.image.decode_image(image_string)\n",
    "        \n",
    "        # normailization\n",
    "        image_normalized = (tf.cast(image_decoded, tf.float32)/127.5) - 1\n",
    "        # resize to given image size\n",
    "        image_resized = tf.image.resize(image_normalized, (IMAGE_SIZE, IMAGE_SIZE))\n",
    "        return image_resized, label\n",
    "        \"\"\"image_casted = tf.cast(image_decoded, tf.float32)\n",
    "        image_resized = tf.image.resize(image_casted, (IMAGE_SIZE, IMAGE_SIZE))\n",
    "        image_preproc = tf.keras.applications.inception_v3.preprocess_input(image_resized)\n",
    "        \n",
    "        return image_preproc, label\"\"\"\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        print(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = (train_data.map(_parse_fn)\\\n",
    "            # .shuffle(buffer_size=5000)\\\n",
    "            .batch(BATCH_SIZE)\n",
    "             )\n",
    "\n",
    "val_data = (val_data.map(_parse_fn)\n",
    "           # .shuffle(buffer_size=5000)\n",
    "           .batch(BATCH_SIZE)\n",
    "           )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ccuulinay/anaconda3/envs/tf2_0/lib/python3.6/site-packages/keras_applications/mobilenet_v2.py:294: UserWarning: `input_shape` is undefined or non-square, or `rows` is not in [96, 128, 160, 192, 224]. Weights for input shape (224, 224) will be loaded as the default.\n",
      "  warnings.warn('`input_shape` is undefined or non-square, '\n"
     ]
    }
   ],
   "source": [
    "# Base model with MobileNetV2\n",
    "IMG_SHAPE = (IMAGE_SIZE, IMAGE_SIZE, 3)\n",
    "\n",
    "base_model = tf.keras.applications.InceptionV3(input_shape=IMG_SHAPE,\n",
    "                                               include_top=False, \n",
    "                                               weights='imagenet')\n",
    "base_model.trainable = False\n",
    "\n",
    "mobilenetV2 = tf.keras.applications.MobileNetV2(input_shape=IMG_SHAPE,\n",
    "                                               include_top=False, \n",
    "                                               weights='imagenet')\n",
    "mobilenetV2.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(lv0_n_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_7\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "mobilenetv2_1.00_224 (Model) (None, 5, 5, 1280)        2257984   \n",
      "_________________________________________________________________\n",
      "global_average_pooling2d_7 ( (None, 1280)              0         \n",
      "_________________________________________________________________\n",
      "dense_14 (Dense)             (None, 4)                 5124      \n",
      "=================================================================\n",
      "Total params: 2,263,108\n",
      "Trainable params: 5,124\n",
      "Non-trainable params: 2,257,984\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Trainable classification head\n",
    "maxpool_layer = tf.keras.layers.GlobalMaxPooling2D()\n",
    "avgpool_layer = tf.keras.layers.GlobalAveragePooling2D()\n",
    "dense_layer = tf.keras.layers.Dense(1024, activation='relu')\n",
    "dropout_layer = tf.keras.layers.Dropout(0.5)\n",
    "prediction_layer = tf.keras.layers.Dense(lv0_n_classes, activation='softmax')\n",
    "\n",
    "learning_rate = 1e-4\n",
    "\n",
    "model = tf.keras.Sequential([\n",
    "    # base_model\n",
    "    mobilenetV2\n",
    "    , avgpool_layer\n",
    "    # , maxpool_layer\n",
    "    # , dense_layer\n",
    "    # , dropout_layer\n",
    "    , prediction_layer\n",
    "])\n",
    "\n",
    "# Now the optimizer is under tf.keras.\n",
    "model.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(lr=learning_rate)\n",
    "    # optimizer=tf.keras.optimizers.SGD(lr=learning_rate, momentum=0.9)\n",
    "    , loss='categorical_crossentropy'\n",
    "    , metrics=['accuracy'])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 30\n",
    "steps_per_epoch = round(len(train_filenames))//BATCH_SIZE\n",
    "val_steps = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Expected a shuffled dataset but input dataset `x` is not shuffled. Please invoke `shuffle()` on input dataset.\n",
      "Epoch 1/30\n",
      "317/317 [==============================] - 60s 189ms/step - loss: 10.8390 - accuracy: 0.1607 - val_loss: 11.7201 - val_accuracy: 0.2109\n",
      "Epoch 2/30\n",
      "317/317 [==============================] - 58s 181ms/step - loss: 10.6787 - accuracy: 0.1718 - val_loss: 11.3149 - val_accuracy: 0.2109\n",
      "Epoch 3/30\n",
      "317/317 [==============================] - 57s 180ms/step - loss: 10.5950 - accuracy: 0.1770 - val_loss: 11.0566 - val_accuracy: 0.2016\n",
      "Epoch 4/30\n",
      "317/317 [==============================] - 57s 180ms/step - loss: 10.5347 - accuracy: 0.1798 - val_loss: 10.8963 - val_accuracy: 0.2078\n",
      "Epoch 5/30\n",
      "317/317 [==============================] - 57s 180ms/step - loss: 10.5077 - accuracy: 0.1834 - val_loss: 10.7719 - val_accuracy: 0.2094\n",
      "Epoch 6/30\n",
      "317/317 [==============================] - 57s 180ms/step - loss: 10.4801 - accuracy: 0.1867 - val_loss: 10.6811 - val_accuracy: 0.2094\n",
      "Epoch 7/30\n",
      "317/317 [==============================] - 57s 180ms/step - loss: 10.4583 - accuracy: 0.1894 - val_loss: 10.6163 - val_accuracy: 0.2031\n",
      "Epoch 8/30\n",
      "317/317 [==============================] - 57s 180ms/step - loss: 10.4106 - accuracy: 0.1909 - val_loss: 10.5621 - val_accuracy: 0.2000\n",
      "Epoch 9/30\n",
      "317/317 [==============================] - 57s 180ms/step - loss: 10.3951 - accuracy: 0.1928 - val_loss: 10.5176 - val_accuracy: 0.2000\n",
      "Epoch 10/30\n",
      " 61/317 [====>.........................] - ETA: 41s - loss: 10.4759 - accuracy: 0.1838"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-81-73e14c13f25b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m                     \u001b[0msteps_per_epoch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m                     \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mval_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrepeat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m                     validation_steps=val_steps)\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/envs/tf2_0/lib/python3.6/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m    789\u001b[0m           \u001b[0mworkers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    790\u001b[0m           \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 791\u001b[0;31m           initial_epoch=initial_epoch)\n\u001b[0m\u001b[1;32m    792\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    793\u001b[0m     \u001b[0;31m# Case 3: Symbolic tensors or Numpy array-like.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tf2_0/lib/python3.6/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, validation_freq, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m   1513\u001b[0m         \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1514\u001b[0m         \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1515\u001b[0;31m         steps_name='steps_per_epoch')\n\u001b[0m\u001b[1;32m   1516\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1517\u001b[0m   def evaluate_generator(self,\n",
      "\u001b[0;32m~/anaconda3/envs/tf2_0/lib/python3.6/site-packages/tensorflow/python/keras/engine/training_generator.py\u001b[0m in \u001b[0;36mmodel_iteration\u001b[0;34m(model, data, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, validation_freq, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch, mode, batch_size, steps_name, **kwargs)\u001b[0m\n\u001b[1;32m    211\u001b[0m     \u001b[0mstep\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    212\u001b[0m     \u001b[0;32mwhile\u001b[0m \u001b[0mstep\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mtarget_steps\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 213\u001b[0;31m       \u001b[0mbatch_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_get_next_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgenerator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    214\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mbatch_data\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    215\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mis_dataset\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tf2_0/lib/python3.6/site-packages/tensorflow/python/keras/engine/training_generator.py\u001b[0m in \u001b[0;36m_get_next_batch\u001b[0;34m(generator, mode)\u001b[0m\n\u001b[1;32m    353\u001b[0m   \u001b[0;34m\"\"\"Retrieves the next batch of input data.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    354\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 355\u001b[0;31m     \u001b[0mgenerator_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgenerator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    356\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mStopIteration\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOutOfRangeError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    357\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tf2_0/lib/python3.6/site-packages/tensorflow/python/data/ops/iterator_ops.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    554\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    555\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m__next__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# For Python 3 compatibility\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 556\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    557\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    558\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_next_internal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tf2_0/lib/python3.6/site-packages/tensorflow/python/data/ops/iterator_ops.py\u001b[0m in \u001b[0;36mnext\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    583\u001b[0m     \"\"\"\n\u001b[1;32m    584\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 585\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_internal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    586\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOutOfRangeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    587\u001b[0m       \u001b[0;32mraise\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tf2_0/lib/python3.6/site-packages/tensorflow/python/data/ops/iterator_ops.py\u001b[0m in \u001b[0;36m_next_internal\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    575\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_resource\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    576\u001b[0m             \u001b[0moutput_types\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_flat_output_types\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 577\u001b[0;31m             output_shapes=self._flat_output_shapes)\n\u001b[0m\u001b[1;32m    578\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    579\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_structure\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_from_compatible_tensor_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mret\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tf2_0/lib/python3.6/site-packages/tensorflow/python/ops/gen_dataset_ops.py\u001b[0m in \u001b[0;36miterator_get_next_sync\u001b[0;34m(iterator, output_types, output_shapes, name)\u001b[0m\n\u001b[1;32m   1938\u001b[0m         \u001b[0m_ctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_context_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_ctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_thread_local_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice_name\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1939\u001b[0m         \u001b[0;34m\"IteratorGetNextSync\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_ctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_post_execution_callbacks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1940\u001b[0;31m         \"output_types\", output_types, \"output_shapes\", output_shapes)\n\u001b[0m\u001b[1;32m   1941\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0m_result\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1942\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0m_core\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_FallbackException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "history = model.fit(train_data.repeat(),\n",
    "                    epochs=num_epochs,\n",
    "                    steps_per_epoch = steps_per_epoch,\n",
    "                    validation_data=val_data.repeat(), \n",
    "                    validation_steps=val_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
